{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\jepey\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jepey\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (4.4.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.3\n",
      "[notice] To update, run: C:\\Users\\jepey\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in c:\\users\\jepey\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\jepey\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: torch==1.12.1 in c:\\users\\jepey\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchvision) (1.12.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jepey\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jepey\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jepey\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jepey\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\jepey\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jepey\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jepey\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->torchvision) (1.26.10)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.3\n",
      "[notice] To update, run: C:\\Users\\jepey\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x254be5934f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import numpy as np\n",
    "np.random.seed(309)\n",
    "random.seed(309)\n",
    "torch.manual_seed(309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6643\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), #converts to pytorch tensor\n",
    "     transforms.Resize((250,250)), #Changed to 250x250 size\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) #normalize the images mean 0.5 and std 0.5\n",
    "transformFlip = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.RandomHorizontalFlip(p=1), #adds horizontal flip to all images\n",
    "     transforms.Resize((250,250)), \n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "transformVerFlip = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.RandomVerticalFlip(p=1), #adds vertical flip to all images\n",
    "     transforms.Resize((250,250)), \n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "#Uses file with outliers removed\n",
    "#Loads training file and transforms it\n",
    "train = torchvision.datasets.ImageFolder(root=\"C:/Users/jepey/OneDrive/Documents/COMP309/ProData/traindata\",transform=transform)\n",
    "#Loads training file and transforms it with horizontal flipping\n",
    "trainF = torchvision.datasets.ImageFolder(root=\"C:/Users/jepey/OneDrive/Documents/COMP309/ProData/traindata\",transform=transformFlip)\n",
    "#Loads training file and transforms it with vertical flipping\n",
    "trainV = torchvision.datasets.ImageFolder(root=\"C:/Users/jepey/OneDrive/Documents/COMP309/ProData/traindata\",transform=transformVerFlip)\n",
    "valT, trainT = torch.utils.data.random_split(\n",
    "    train, (int(len(train)*0.3),len(train)-int(len(train)*0.3)) #Gets unaugmented validation data of size 20% of whole set\n",
    ")\n",
    "useF, trashF = torch.utils.data.random_split(\n",
    "    trainF, (int(len(trainF)*0.25),len(trainF)-int(len(trainF)*0.25)) #Gets 25% of the horizontal flipped images to use\n",
    ")\n",
    "useV, trashV = torch.utils.data.random_split(\n",
    "    trainV, (int(len(trainV)*0.25),len(trainV)-int(len(trainV)*0.25)) #Gets 25% of the vertical flipped images to use\n",
    ")\n",
    "\n",
    "fullTrain = trainT + useF + useV\n",
    "\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(fullTrain, batch_size=64,\n",
    "                                          shuffle=True)\n",
    "valLoader = torch.utils.data.DataLoader(valT, batch_size=64,\n",
    "                                          shuffle=True)\n",
    "print(len(fullTrain))\n",
    "print(len(trainLoader))\n",
    "print(len(valLoader))\n",
    "# classes for computing accuracy\n",
    "classes = ('cherry','strawberry','tomato')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for computing training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compares actual labels to labels predicted\n",
    "def accuracy(predictions, labels):\n",
    "    #For each row picks index with highest value as class eg 0,1,2\n",
    "    classes = torch.argmax(predictions, dim=1)\n",
    "    #If prediction is correct add to counter\n",
    "    return torch.mean((classes == labels).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Validation Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValScore(valLoader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  # Since we're not training, we don't need to calculate the gradients for our outputs\n",
    "  with torch.no_grad():\n",
    "      for data in valLoader: #Iterates through validation set\n",
    "          images, labels = data\n",
    "          # calculate outputs by running images through the network\n",
    "          outputs = mlp(images)\n",
    "          # the class with the highest energy is what we choose as prediction\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          #Adds to total counter\n",
    "          total += labels.size(0) \n",
    "          #If correct add to counter\n",
    "          correct += (predicted == labels).sum().item()\n",
    "  return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #3 linear layers to make the classifications to 3 classes\n",
    "        self.fc1 = nn.Linear(250*250*3, 120) #After flattening take each RGB value gor every pixel and reduce it to 120\n",
    "        self.fc2 = nn.Linear(120, 84) #Reduce further to 84\n",
    "        self.fc3 = nn.Linear(84, 3) #Reduce to number of classes being 3\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        #print(x.size()) for testing\n",
    "         #Applies 3 linear layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x)) \n",
    "        x = self.fc3(x)\n",
    "        #Returns flattening as batch to be used for classification\n",
    "        return x\n",
    "\n",
    "#Creates initial model\n",
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize loss criteria and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizes model and computes accuracies and loss at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochList = []\n",
    "valList = []\n",
    "accList = []\n",
    "lossList = []\n",
    "for epoch in range(30):  # loop over the dataset 30 times\n",
    "    running_accuracy=0.0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainLoader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients  as they typically accumulate\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        #Get outputs from current model\n",
    "        outputs = mlp(inputs)\n",
    "        #Calculate Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        #Runs autograd to fill in gradients of optimizer using loss\n",
    "        loss.backward()\n",
    "        #Updates optimizer parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        running_accuracy += accuracy(outputs, labels) \n",
    "    running_loss += loss.item()\n",
    "    vScore = getValScore(valLoader)\n",
    "    print(\"Epoch = {}\".format(epoch+1))\n",
    "    print(\"Validation Accuracy = {}\".format(vScore))\n",
    "    print(\"Accuracy = {}\".format(running_accuracy/len(trainLoader)))\n",
    "    print(\"Loss = {}\".format(running_loss))\n",
    "    epochList.append(epoch+1)\n",
    "    accList.append(running_accuracy/len(trainLoader))\n",
    "    valList.append(vScore)\n",
    "    lossList.append(running_loss)\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for drawing graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochList,lossList)\n",
    "plt.title(\"Epoch vs Loss MLP\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(accList,label=\"Train Accuracy\")\n",
    "plt.plot(valList,label=\"Validation Accuracy\")\n",
    "plt.title(\"Epoch vs Accuracy MLP\")\n",
    "plt.xlabel('No. epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for base CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValScoreNN(valLoader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  # Since we're not training, we don't need to calculate the gradients for our outputs\n",
    "  with torch.no_grad():\n",
    "      for data in valLoader:\n",
    "          i = i+1\n",
    "          images, labels = data\n",
    "          # calculate outputs by running images through the network\n",
    "          outputs = net(images)\n",
    "          # the class with the highest energy is what we choose as prediction\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          #Adds to total counter\n",
    "          total += labels.size(0)\n",
    "          #If correct add to counter\n",
    "          correct += (predicted == labels).sum().item()\n",
    "  return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) #3 channels for RGB to 6 channels with kernel size 5x5\n",
    "        self.pool = nn.MaxPool2d(2, 2) #Max pooling with size of 2x2\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) #6 channels from above to 16 channels with kernel size 5x5\n",
    "        self.fc1 = nn.Linear(1296, 120) #Linear layer to reduce layers to 120\n",
    "        self.fc2 = nn.Linear(120, 84) #Reduce layers to 84\n",
    "        self.fc3 = nn.Linear(84, 3) #Reduce to the number of classes being 3\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) #Applies the first convolution layer with ReLu and apply Max pooling to that\n",
    "        #print(x.size())\n",
    "        x = self.pool(F.relu(self.conv2(x))) #Applies the second convolution layer with ReLu and apply Max pooling to that\n",
    "        #print(x.size())\n",
    "        x = torch.flatten(x, 1) # Flattens all dimensions except batch\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.fc1(x)) #Applies Linear layer with ReLu\n",
    "        x = F.relu(self.fc2(x)) #Applies Linear layer with ReLu\n",
    "        x = self.fc3(x) #Gets the class\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochListNN = []\n",
    "valListNN = []\n",
    "accListNN = []\n",
    "lossListNN = []\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_accuracy=0.0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainLoader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients  as they typically accumulate\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        #Get outputs from current model\n",
    "        outputs = net(inputs)\n",
    "        #Calculate Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        #Runs autograd to fill in gradients of optimizer using loss\n",
    "        loss.backward()\n",
    "        #Updates optimizer parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        running_accuracy += accuracy(outputs, labels)\n",
    "    running_loss += loss.item()\n",
    "    vScore = getValScoreNN(valLoader)\n",
    "    print(\"Epoch = {}\".format(epoch+1))\n",
    "    print(\"Validation Accuracy = {}\".format(vScore))\n",
    "    print(\"Accuracy = {}\".format(running_accuracy/len(trainLoader)))\n",
    "    print(\"Loss = {}\".format(running_loss))\n",
    "    epochListNN.append(epoch+1)\n",
    "    accListNN.append(running_accuracy/len(trainLoader))\n",
    "    valListNN.append(vScore)\n",
    "    lossListNN.append(running_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochListNN,lossListNN)\n",
    "plt.title(\"Epoch vs Loss CNN\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(accListNN,label=\"Train Accuracy\")\n",
    "plt.plot(valListNN,label=\"Validation Accuracy\")\n",
    "plt.title(\"Epoch vs Accuracy CNN\")\n",
    "plt.xlabel('No. epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Model Using VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValScoreVGG(valLoader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  # Since we're not training, we don't need to calculate the gradients for our outputs\n",
    "  with torch.no_grad():\n",
    "      for data in valLoader: #Iterates through validation set\n",
    "          images, labels = data\n",
    "          # Calculate outputs by running images through the network\n",
    "          outputs = model(images)\n",
    "          # The class with the highest energy is what we choose as prediction\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          #Counts images seen\n",
    "          total += labels.size(0)\n",
    "          #Adds to correct counter if the predicted label is correct\n",
    "          correct += (predicted == labels).sum().item()\n",
    "  return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    " \n",
    "#Uses torches torch.hub repository to get the vgg19 model and set pretrained to true to use ImageNet pretrained weights\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\n",
    "#Use Cross Entropy so no need to softmax\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
    "\n",
    "#Resets lists for storing values at each epoch\n",
    "epochListVGG = []\n",
    "valListVGG = []\n",
    "accListVGG = []\n",
    "lossListVGG = []\n",
    "for epoch in range(7):  # loop over the dataset 7 times\n",
    "    running_accuracy=0.0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainLoader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels] labels is 0,1 or 2 for class and input is tensor image\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients as they typically accumulate\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        #Get outputs from current model\n",
    "        outputs = model(inputs)\n",
    "        #Calculate Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        #Runs autograd to fill in gradients of optimizer using loss\n",
    "        loss.backward()\n",
    "        #Updates optimizer parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        #calculates accuracy for each batch\n",
    "        running_accuracy += accuracy(outputs, labels) \n",
    "\n",
    "    #Calculates and prints statistics\n",
    "    running_loss += loss.item()\n",
    "    vScore = getValScoreVGG(valLoader)\n",
    "    print(\"Epoch = {}\".format(epoch+1))\n",
    "    print(\"Validation Accuracy = {}\".format(vScore))\n",
    "    print(\"Accuracy = {}\".format(running_accuracy/len(trainLoader)))\n",
    "    print(\"Loss = {}\".format(running_loss))\n",
    "    epochListVGG.append(epoch+1)\n",
    "    accListVGG.append(running_accuracy/len(trainLoader))\n",
    "    valListVGG.append(vScore)\n",
    "    lossListVGG.append(running_loss)\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " torch.save(model.state_dict(), './model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG19 consists of Convolution 3x3 layers (to detect features in input) with stride 1,1 and padding 1,1,1,1 (to keep spatial resolution) then ReLu layer (non-linearity to reduce training time and classify better by smoothing and making more distinct boundaries) followed by Max Pooling (reduce height and width and fix distorted images) and then a few Fully Connected layers with ReLu (process data into NN through linear rectifier activation function it increases non-linearity) and 50% dropout (to reduce overfitting by dropping units randomly and connections to reduce dependency on one unit) and finally a SoftMax layer (expontentiates logits to make posistive and scale so sum to 1 to make them probabilities not really needed since using Cross Enthropy). \n",
    "\n",
    "The model is pretrained using ImageNet which is a collection of over 14million images which makes for a smart model to start with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs for VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochListVGG,lossListVGG)\n",
    "plt.title(\"Epoch vs Loss VGG\")\n",
    "plt.show()  \n",
    "\n",
    "plt.plot(epochListVGG,accListNN,label=\"Train Accuracy\")\n",
    "plt.plot(epochListVGG,valListNN,label=\"Validation Accuracy\")\n",
    "plt.title(\"Epoch vs Accuracy VGG\")\n",
    "plt.xlabel('No. epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Saved Final Model and testing validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\jepey/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9721595184349134\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\n",
    "model.load_state_dict(torch.load('./VGG-Fold1-250.pth'))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "  # Since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in valLoader:\n",
    "        images, labels = data\n",
    "          # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "          # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #Adds to total\n",
    "        total += labels.size(0)\n",
    "        #Adds to correct total if predicted label is correct\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(correct/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f68840bced8f1787275eae5c0d3b89c82b58da07ce5bc3135d36b1683ecc2be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
